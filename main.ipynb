{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state\n",
    "class BMIState(TypedDict):\n",
    "\n",
    "    weight_kg: float\n",
    "    height_m: float\n",
    "    bmi: float\n",
    "    category: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bmi(state: BMIState) -> BMIState:\n",
    "    weight = state['weight_kg']\n",
    "    height = state[\"height_m\"]\n",
    "\n",
    "    bmi = weight/(height**2)\n",
    "\n",
    "    state[\"bmi\"] = round(bmi, 2)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_bmi(state: BMIState) -> BMIState:\n",
    "    bmi = state[\"bmi\"]\n",
    "\n",
    "    if bmi < 18.5:\n",
    "        state[\"category\"] = \"Underweight\"\n",
    "    elif 18.5 <= bmi < 25:\n",
    "        state[\"category\"] = \"Normal\"\n",
    "    elif 25 <= bmi < 30:\n",
    "        state[\"category\"] = \"Overweight\"\n",
    "    else:\n",
    "        state[\"category\"] = \"Obese\"\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph\n",
    "graph = StateGraph(BMIState)\n",
    "\n",
    "# Add nodes to graph\n",
    "graph.add_node('calculate_bmi', calculate_bmi)\n",
    "graph.add_node('label_bmi', label_bmi)\n",
    "\n",
    "# Add edges to graph\n",
    "graph.add_edge(START, 'calculate_bmi')\n",
    "graph.add_edge('calculate_bmi', 'label_bmi')\n",
    "graph.add_edge('label_bmi', END)\n",
    "\n",
    "# Compile the graph \n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the graph\n",
    "initial_state = {\"weight_kg\": 64, \"height_m\": 1.68}\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(workflow.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_groq import ChatGroq\n",
    "from IPython.display import Image\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "\n",
    "class LLMState(TypedDict):\n",
    "\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_qa(state: LLMState) -> LLMState:\n",
    "    \n",
    "    # Extract the question from state\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Form a prompt\n",
    "    prompt = f\"Answer the following question {question}\"\n",
    "\n",
    "    # Ask the questions\n",
    "    answer = model.invoke(prompt).content\n",
    "\n",
    "    # Update the answer in the state\n",
    "\n",
    "    state[\"answer\"] = answer\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Graph\n",
    "graph = StateGraph(LLMState)\n",
    "\n",
    "# Add nodes to Graph\n",
    "graph.add_node(\"llm_qa\", llm_qa)\n",
    "\n",
    "# Add edges to the graph\n",
    "graph.add_edge(START, \"llm_qa\")\n",
    "graph.add_edge(\"llm_qa\", END)\n",
    "\n",
    "# Compile\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(workflow.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"question\": \"How far is moon from the Earth?\"}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from IPython.display import Image\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "\n",
    "class BlogState(TypedDict):\n",
    "\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: BlogState) -> BlogState:\n",
    "\n",
    "    # fetch title\n",
    "    title = state[\"title\"]\n",
    "\n",
    "    # call llm gen outline\n",
    "    prompt = f\"Generate a detailed outline for a blog on the topic - {title}\"\n",
    "    outline = model.invoke(prompt).content\n",
    "\n",
    "    # Update state\n",
    "\n",
    "    state[\"outline\"] = outline\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state: BlogState) -> BlogState:\n",
    "\n",
    "    # fetch title\n",
    "    title = state[\"title\"]\n",
    "    outline = state[\"outline\"]\n",
    "\n",
    "    prompt = f\"Write a etailed blog on the title - {title} using the following outline \\n {outline}\"\n",
    "    content = model.invoke(prompt).content\n",
    "\n",
    "    # Update state\n",
    "\n",
    "    state[\"content\"] = content\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define graph\n",
    "\n",
    "graph = StateGraph(BlogState)\n",
    "\n",
    "# Define Nodes\n",
    "graph.add_node(\"create_outline\", create_outline)\n",
    "graph.add_node(\"create_blog\", create_blog)\n",
    "\n",
    "# Define Edges\n",
    "graph.add_edge(START, \"create_outline\")\n",
    "graph.add_edge(\"create_outline\", \"create_blog\")\n",
    "graph.add_edge(\"create_blog\", END)\n",
    "\n",
    "\n",
    "# Compile\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(workflow.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"title\": \"Rise of AI in Bangladesh\"}\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_state[\"outline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_state[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Workflows in LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "\n",
    "class AnalysisPlayerPerformanceState(TypedDict):\n",
    "\n",
    "    runs: int\n",
    "    balls: int\n",
    "    fours: int\n",
    "    sixes: int\n",
    "    strike_rate: float\n",
    "    balls_per_boundary: float\n",
    "    boundary_percent: float\n",
    "    summary: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sr(state: AnalysisPlayerPerformanceState):\n",
    "\n",
    "    sr = (state[\"runs\"]/state[\"balls\"])*100\n",
    "\n",
    "    return {\"strike_rate\": sr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bpb(state: AnalysisPlayerPerformanceState):\n",
    "\n",
    "    bpb = (state[\"balls\"]/state[\"fours\"] + state[\"sixes\"])\n",
    "\n",
    "    return {\"balls_per_boundary\": bpb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_boundary_percent(state: AnalysisPlayerPerformanceState):\n",
    "\n",
    "    boundary_percent = (((state[\"fours\"]*4) + (state[\"sixes\"]*6))/state[\"runs\"])*100\n",
    "\n",
    "    return {\"boundary_percent\": boundary_percent}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(state: AnalysisPlayerPerformanceState):\n",
    "\n",
    "    summary = f\"\"\"\n",
    "    Strike Rate - {state[\"strike_rate\"]} \\n\n",
    "    Balls per boundary - {state[\"balls_per_boundary\"]} \\n\n",
    "    Boundary percent - {state[\"boundary_percent\"]}\n",
    "    \"\"\"\n",
    "\n",
    "    return {\"summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph\n",
    "graph = StateGraph(AnalysisPlayerPerformanceState)\n",
    "\n",
    "# Add Node\n",
    "graph.add_node(\"calculate_sr\", calculate_sr)\n",
    "graph.add_node(\"calculate_bpb\", calculate_bpb)\n",
    "graph.add_node(\"calculate_boundary_percent\", calculate_boundary_percent)\n",
    "graph.add_node(\"summary\", summary)\n",
    "\n",
    "# Add Edge\n",
    "graph.add_edge(START, 'calculate_sr')\n",
    "graph.add_edge(START, 'calculate_bpb')\n",
    "graph.add_edge(START, 'calculate_boundary_percent')\n",
    "\n",
    "graph.add_edge(\"calculate_sr\", 'summary')\n",
    "graph.add_edge(\"calculate_bpb\", 'summary')\n",
    "graph.add_edge(\"calculate_boundary_percent\", 'summary')\n",
    "\n",
    "graph.add_edge(\"calculate_boundary_percent\", END)\n",
    "\n",
    "# Compile\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(workflow.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"runs\": 100,\n",
    "    \"balls\": 89,\n",
    "    \"fours\": 6,\n",
    "    \"sixes\": 3\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "\n",
    "    feedback: str = Field(description=\"Detailed feedback for the essay\")\n",
    "    score: int = Field(description=\"Score out of 10\", ge = 0, le = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(EvaluationSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = \"\"\"Bangladesh in the Age of AI\n",
    "As the world enters a transformative era defined by artificial intelligence (AI), Bangladesh stands at a critical juncture — one where it can either emerge as a global leader in AI innovation or risk falling behind in the technology race. The age of AI brings with it immense promise as well as unprecedented challenges, and how Bangladesh navigates this landscape will shape its socio-economic and geopolitical future.\n",
    "\n",
    "Bangladesh's strengths in the AI domain are rooted in its vast pool of skilled engineers, a thriving IT industry, and a growing startup ecosystem. With over 5 million STEM graduates annually and a burgeoning base of AI researchers, Bangladesh possesses the intellectual capital required to build cutting-edge AI systems. Institutions like IITs, IIITs, and IISc have begun fostering AI research, while private players such as TCS, Infosys, and Wipro are integrating AI into their global services. In 2020, the government launched the National AI Strategy (AI for All) with a focus on inclusive growth, aiming to leverage AI in healthcare, agriculture, education, and smart mobility.\n",
    "\n",
    "One of the most promising applications of AI in Bangladesh lies in agriculture, where predictive analytics can guide farmers on optimal sowing times, weather forecasts, and pest control. In healthcare, AI-powered diagnostics can help address Bangladesh’s doctor-patient ratio crisis, particularly in rural areas. Educational platforms are increasingly using AI to personalize learning paths, while smart governance tools are helping improve public service delivery and fraud detection.\n",
    "\n",
    "However, the path to AI-led growth is riddled with challenges. Chief among them is the digital divide. While metropolitan cities may embrace AI-driven solutions, rural Bangladesh continues to struggle with basic internet access and digital literacy. The risk of job displacement due to automation also looms large, especially for low-skilled workers. Without effective skilling and re-skilling programs, AI could exacerbate existing socio-economic inequalities.\n",
    "\n",
    "Another pressing concern is data privacy and ethics. As AI systems rely heavily on vast datasets, ensuring that personal data is used transparently and responsibly becomes vital. Bangladesh is still shaping its data protection laws, and in the absence of a strong regulatory framework, AI systems may risk misuse or bias.\n",
    "\n",
    "To harness AI responsibly, Bangladesh must adopt a multi-stakeholder approach involving the government, academia, industry, and civil society. Policies should promote open datasets, encourage responsible innovation, and ensure ethical AI practices. There is also a need for international collaboration, particularly with countries leading in AI research, to gain strategic advantage and ensure interoperability in global systems.\n",
    "\n",
    "Bangladesh’s demographic dividend, when paired with responsible AI adoption, can unlock massive economic growth, improve governance, and uplift marginalized communities. But this vision will only materialize if AI is seen not merely as a tool for automation, but as an enabler of human-centered development.\n",
    "\n",
    "In conclusion, Bangladesh in the age of AI is a story in the making — one of opportunity, responsibility, and transformation. The decisions we make today will not just determine Bangladesh’s AI trajectory, but also its future as an inclusive, equitable, and innovation-driven society.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {essay}'\n",
    "structured_model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model.invoke(prompt).feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model.invoke(prompt).score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPSCState(TypedDict):\n",
    "    \n",
    "    essay: str\n",
    "    language_feedback: str\n",
    "    analysis_feedback: str\n",
    "    clarity_feedback: str\n",
    "    overall_feedback: str\n",
    "    individual_scores: Annotated[list[int], operator.add]\n",
    "    avg_score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language(state: UPSCState):\n",
    "\n",
    "    prompt = f'Evaluate the language quality of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'language_feedback': output.feedback, 'individual_scores': [output.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analysis(state: UPSCState):\n",
    "\n",
    "    prompt = f'Evaluate the depth of analysis of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'analysis_feedback': output.feedback, 'individual_scores': [output.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_thought(state: UPSCState):\n",
    "\n",
    "    prompt = f'Evaluate the clarity of thought of the following essay and provide a feedback and assign a score out of 10 \\n {state[\"essay\"]}'\n",
    "    output = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'clarity_feedback': output.feedback, 'individual_scores': [output.score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(state: UPSCState):\n",
    "\n",
    "    # summary feedback\n",
    "    prompt = f'Based on the following feedbacks create a summarized feedback \\n language feedback - {state[\"language_feedback\"]} \\n depth of analysis feedback - {state[\"analysis_feedback\"]} \\n clarity of thought feedback - {state[\"clarity_feedback\"]}'\n",
    "    overall_feedback = model.invoke(prompt).content\n",
    "\n",
    "    # avg calculate\n",
    "    avg_score = sum(state['individual_scores'])/len(state['individual_scores'])\n",
    "\n",
    "    return {'overall_feedback': overall_feedback, 'avg_score': avg_score}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Graph\n",
    "graph = StateGraph(UPSCState)\n",
    "\n",
    "# Add Node\n",
    "graph.add_node(\"evaluate_language\", evaluate_language)\n",
    "graph.add_node(\"evaluate_analysis\", evaluate_analysis)\n",
    "graph.add_node(\"evaluate_thought\", evaluate_thought)\n",
    "graph.add_node(\"final_evaluation\", final_evaluation)\n",
    "\n",
    "\n",
    "# Add Edge\n",
    "graph.add_edge(START, 'evaluate_language')\n",
    "graph.add_edge(START, 'evaluate_analysis')\n",
    "graph.add_edge(START, 'evaluate_thought')\n",
    "\n",
    "graph.add_edge('evaluate_language', 'final_evaluation')\n",
    "graph.add_edge('evaluate_analysis', 'final_evaluation')\n",
    "graph.add_edge('evaluate_thought', 'final_evaluation')\n",
    "\n",
    "graph.add_edge('final_evaluation', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay2 = \"\"\"Bangladesh and AI Time\n",
    "\n",
    "Now world change very fast because new tech call Artificial Intel… something (AI). Bangladesh also want become big in this AI thing. If work hard, Bangladesh can go top. But if no careful, Bangladesh go back.\n",
    "\n",
    "Bangladesh have many good. We have smart student, many engine-ear, and good IT peoples. Big company like TCS, Infosys, Wipro already use AI. Government also do program “AI for All”. It want AI in farm, doctor place, school and transport.\n",
    "\n",
    "In farm, AI help farmer know when to put seed, when rain come, how stop bug. In health, AI help doctor see sick early. In school, AI help student learn good. Government office use AI to find bad people and work fast.\n",
    "\n",
    "But problem come also. First is many villager no have phone or internet. So AI not help them. Second, many people lose job because AI and machine do work. Poor people get more bad.\n",
    "\n",
    "One more big problem is privacy. AI need big big data. Who take care? Bangladesh still make data rule. If no strong rule, AI do bad.\n",
    "\n",
    "Bangladesh must all people together – govern, school, company and normal people. We teach AI and make sure AI not bad. Also talk to other country and learn from them.\n",
    "\n",
    "If Bangladesh use AI good way, we become strong, help poor and make better life. But if only rich use AI, and poor no get, then big bad thing happen.\n",
    "\n",
    "So, in short, AI time in Bangladesh have many hope and many danger. We must go right road. AI must help all people, not only some. Then Bangladesh grow big and world say \"good job Bangladesh\".\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intial_state = {\n",
    "    'essay': essay2\n",
    "}\n",
    "\n",
    "workflow.invoke(intial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
